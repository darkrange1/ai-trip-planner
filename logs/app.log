2025-12-28 21:26:04,818 - main - INFO - Received query: Plan to trip paris 5 days
2025-12-28 21:26:04,818 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:26:04,818 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:26:04,819 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:26:04,819 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:26:04,819 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:26:04,819 - main - ERROR - Error processing query: 'llm'
Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 52, in query_travel_agent
    graph = GraphBuilder(model_provider="google")
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 17, in __init__
    self.llm = self.model_loader.load_llm()
               ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/utils/model_loader.py", line 43, in load_llm
    model_name = self.config["llm"]["google"]["model_name"]
                 ~~~~~~~~~~~^^^^^^^
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/utils/model_loader.py", line 17, in __getitem__
    return self.config[key]
           ~~~~~~~~~~~^^^^^
KeyError: 'llm'
2025-12-28 21:27:11,716 - main - INFO - Received query: plan trip paris 5 days
2025-12-28 21:27:11,716 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:27:11,716 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:27:11,718 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:27:11,718 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:27:11,718 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:27:11,864 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:27:11,870 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:27:12,403 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:27:12,406 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:27:15,109 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:27:15,488 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:27:16,674 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:27:17,199 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:27:34,458 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:27:34,459 - main - INFO - Query processed successfully
2025-12-28 21:36:48,539 - main - INFO - Received query: Sanat müzelerine gidecegim bodrumda nerelere gideyim
2025-12-28 21:36:48,539 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:36:48,539 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:36:48,540 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:36:48,540 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:36:48,541 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:36:48,658 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:36:48,665 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:36:49,054 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:36:49,056 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:36:51,419 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:36:52,032 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:36:53,348 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:36:53,473 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:36:58,497 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:36:58,498 - main - INFO - Query processed successfully
2025-12-28 21:38:18,154 - main - INFO - Received query: Paris gezisi planla
2025-12-28 21:38:18,154 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:38:18,154 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:38:18,155 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:38:18,155 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:38:18,156 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:38:18,271 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:38:18,278 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:38:18,593 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:38:18,595 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:38:20,816 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:38:21,219 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:38:22,863 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:38:23,582 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:38:50,409 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:38:50,410 - main - INFO - Query processed successfully
2025-12-28 21:41:27,994 - main - INFO - Received query: Paris gezisi planla
2025-12-28 21:41:27,994 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:41:27,994 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:41:27,995 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:41:27,996 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:41:27,996 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:41:28,121 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:41:28,127 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:41:28,432 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:41:28,434 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:41:30,051 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:41:30,466 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:41:31,654 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:41:32,146 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:41:34,997 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:41:35,106 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:41:37,912 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:41:37,915 - main - ERROR - Error processing query: can't multiply sequence by non-int of type 'float'
Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 799, in _func
    outputs = list(
        executor.map(self._run_one, tool_calls, input_types, tool_runtimes)
    )
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ~~~~~~~~~~^^^^^^^^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/usr/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/config.py", line 551, in _wrapped_fn
    return contexts.pop().run(fn, *args)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 1010, in _run_one
    return self._execute_tool_sync(tool_request, input_type, config)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 959, in _execute_tool_sync
    content = _handle_tool_error(e, flag=self._handle_tool_errors)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 424, in _handle_tool_error
    content = flag(e)  # type: ignore [assignment, call-arg]
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 381, in _default_handle_tool_errors
    raise e
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 916, in _execute_tool_sync
    response = tool.invoke(call_args, config)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/base.py", line 629, in invoke
    return self.run(tool_input, **kwargs)
           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/base.py", line 981, in run
    raise error_to_raise
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/base.py", line 947, in run
    response = context.run(self._run, *tool_args, **tool_kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/structured.py", line 93, in _run
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/tools/expense_calculator_tool.py", line 15, in estimate_total_hotel_cost
    return self.calculator.multiply(price_per_night, total_days)
           ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/utils/expense_calculator.py", line 14, in multiply
    return a * b
           ~~^~~
TypeError: can't multiply sequence by non-int of type 'float'
During task with name 'tools' and id '7173e524-dea9-15a3-4201-07afdce0efe0'
2025-12-28 21:41:48,440 - main - INFO - Received query: Paris gezisi planla
2025-12-28 21:41:48,440 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:41:48,440 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:41:48,441 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:41:48,441 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:41:48,441 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:41:48,519 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:41:48,524 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:41:48,802 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:41:48,804 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:41:51,657 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:41:52,149 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:41:54,116 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:41:54,232 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:42:16,745 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:42:16,746 - main - INFO - Query processed successfully
2025-12-28 21:43:01,859 - main - INFO - Received query: Paris gezisinde hangi restorantlara ve müzelere gidelim
2025-12-28 21:43:01,859 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:43:01,859 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:43:01,860 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:43:01,860 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:43:01,860 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:43:01,937 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:43:01,942 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:43:02,357 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:43:02,358 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:43:04,976 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:43:05,489 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:43:08,240 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:43:08,241 - main - INFO - Query processed successfully
2025-12-28 21:47:01,960 - main - INFO - Received query: Sanat müzelerine 5 günlük tatil ayarla paris te
2025-12-28 21:47:01,960 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:47:01,960 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:47:01,961 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:47:01,961 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:47:01,961 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:47:02,071 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:47:02,077 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:47:02,383 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:47:02,385 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:47:06,768 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:47:12,351 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:47:18,730 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:47:18,731 - main - INFO - Query processed successfully
2025-12-28 21:47:37,939 - main - INFO - Received query: Sanat müzelerine 5 günlük tatil ayarla paris te ancak restoranda öner
2025-12-28 21:47:37,939 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:47:37,939 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:47:37,940 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:47:37,940 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:47:37,940 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:47:38,014 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:47:38,020 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:47:38,604 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:47:38,606 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:47:41,458 - agent.agentic_workflow - INFO - LLM response received
2025-12-28 21:47:41,702 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:48:15,682 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 44.388343518s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 44.388343518s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 44.388343518s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}
During task with name 'agent' and id 'ad05e146-0f20-9317-c327-e29f1a2a8587'
2025-12-28 21:49:40,322 - main - INFO - Received query: parise gidecegimde bana restorant öner
2025-12-28 21:49:40,322 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:49:40,322 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:49:40,323 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:49:40,323 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:49:40,323 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:49:40,410 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:49:40,414 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:49:40,878 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:49:40,880 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:50:16,127 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 43.931299998s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '43s'}]}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 43.931299998s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '43s'}]}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 43.931299998s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '43s'}]}}
During task with name 'agent' and id '890e9cb7-eba4-eb58-54b6-4f8b3371f4a8'
2025-12-28 21:51:10,230 - main - INFO - Received query: parise gidecegimde bana restorant öner
2025-12-28 21:51:10,231 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:51:10,231 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:51:10,232 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:51:10,232 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:51:10,232 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:51:10,304 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:51:10,310 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:51:10,601 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:51:10,602 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:51:44,063 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 15.975644158s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 15.975644158s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 15.975644158s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}
During task with name 'agent' and id 'bec53576-1fe4-004f-e430-97f5570c610a'
2025-12-28 21:51:48,799 - main - INFO - Received query: parise gidecegimde bana restorant öner
2025-12-28 21:51:48,799 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:51:48,799 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:51:48,800 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:51:48,800 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:51:48,800 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:51:48,879 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:51:48,883 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:51:49,139 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:51:49,140 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:52:23,253 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 36.798489811s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 36.798489811s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 36.798489811s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}
During task with name 'agent' and id '3b22d746-3cfa-426f-c17f-ca0b7cea8019'
2025-12-28 21:52:23,261 - main - INFO - Received query: parise gidecegimde bana restorant öner
2025-12-28 21:52:23,261 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:52:23,261 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:52:23,262 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:52:23,262 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:52:23,262 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:52:23,349 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:52:23,354 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:52:23,681 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:52:23,682 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:52:58,994 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 1.053552523s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 1.053552523s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 1.053552523s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}
During task with name 'agent' and id '4b81ad40-1cc3-287f-6d83-9183fbf369f7'
2025-12-28 21:56:40,164 - main - INFO - Received query: paris restoran öner 
2025-12-28 21:56:40,164 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 21:56:40,164 - utils.model_loader - INFO - Loaded config.....
2025-12-28 21:56:40,165 - utils.model_loader - INFO - LLM loading...
2025-12-28 21:56:40,165 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 21:56:40,165 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 21:56:40,244 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 21:56:40,249 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 21:56:40,593 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 21:56:40,595 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 21:57:15,777 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 44.26781654s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 44.26781654s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 44.26781654s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}
During task with name 'agent' and id '96a136d4-373f-6601-e8d9-0a58fd04e939'
2025-12-28 22:04:20,576 - main - INFO - Received query: Bana parise tatil ayarla 5 günlük
2025-12-28 22:04:20,577 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 22:04:20,577 - utils.model_loader - INFO - Loaded config.....
2025-12-28 22:04:20,578 - utils.model_loader - INFO - LLM loading...
2025-12-28 22:04:20,578 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 22:04:20,578 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 22:04:20,688 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 22:04:20,694 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 22:04:21,072 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 22:04:21,075 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 22:04:55,671 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
During task with name 'agent' and id '2ce67a86-7f03-bde7-41c2-b7ecc91b0ea1'
2025-12-28 22:05:41,615 - main - INFO - Received query: Bana parise tatil ayarla 5 günlük
2025-12-28 22:05:41,616 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 22:05:41,616 - utils.model_loader - INFO - Loaded config.....
2025-12-28 22:05:41,618 - utils.model_loader - INFO - LLM loading...
2025-12-28 22:05:41,618 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 22:05:41,618 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 22:05:41,697 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 22:05:41,702 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 22:05:41,990 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 22:05:41,992 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 22:05:42,315 - main - ERROR - Error processing query: Error calling model 'gemini-1.5-flash' (NOT_FOUND): 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-1.5-flash' (NOT_FOUND): 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}
During task with name 'agent' and id '68108c32-9fe1-1203-7012-0a9a55d4c1dc'
2025-12-28 22:05:43,920 - main - INFO - Received query: Bana parise tatil ayarla 5 günlük
2025-12-28 22:05:43,920 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 22:05:43,920 - utils.model_loader - INFO - Loaded config.....
2025-12-28 22:05:43,921 - utils.model_loader - INFO - LLM loading...
2025-12-28 22:05:43,921 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 22:05:43,921 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 22:05:43,995 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 22:05:44,000 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 22:05:44,288 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 22:05:44,290 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 22:05:44,598 - main - ERROR - Error processing query: Error calling model 'gemini-1.5-flash' (NOT_FOUND): 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-1.5-flash' (NOT_FOUND): 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}
During task with name 'agent' and id '8982469c-4387-b6b3-9300-6413bd4defb2'
2025-12-28 22:06:34,386 - main - INFO - Received query: Bana parise tatil ayarla 5 günlük
2025-12-28 22:06:34,386 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 22:06:34,386 - utils.model_loader - INFO - Loaded config.....
2025-12-28 22:06:34,387 - utils.model_loader - INFO - LLM loading...
2025-12-28 22:06:34,387 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 22:06:34,387 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 22:06:34,464 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 22:06:34,470 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 22:06:35,058 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 22:06:35,060 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 22:07:08,945 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
During task with name 'agent' and id '0be2e777-3e15-3d39-76b1-6f2251e8c5e5'
2025-12-28 22:07:08,953 - main - INFO - Received query: Bana parise tatil ayarla 5 günlük
2025-12-28 22:07:08,953 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 22:07:08,953 - utils.model_loader - INFO - Loaded config.....
2025-12-28 22:07:08,954 - utils.model_loader - INFO - LLM loading...
2025-12-28 22:07:08,954 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 22:07:08,954 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 22:07:09,027 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 22:07:09,032 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 22:07:09,321 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 22:07:09,323 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 22:07:43,963 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
During task with name 'agent' and id '4dd60f9f-991a-7680-9198-fa2e9831227e'
2025-12-28 22:07:43,972 - main - INFO - Received query: Bana parise tatil ayarla 5 günlük
2025-12-28 22:07:43,972 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 22:07:43,972 - utils.model_loader - INFO - Loaded config.....
2025-12-28 22:07:43,973 - utils.model_loader - INFO - LLM loading...
2025-12-28 22:07:43,973 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 22:07:43,973 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 22:07:44,052 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 22:07:44,057 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 22:07:44,366 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 22:07:44,367 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 22:08:19,488 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
During task with name 'agent' and id 'c7574e6a-6cd6-3403-6edc-c646e472a7f5'
2025-12-28 22:08:19,505 - main - INFO - Received query: Bana parise tatil ayarla 5 günlük
2025-12-28 22:08:19,506 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-28 22:08:19,506 - utils.model_loader - INFO - Loaded config.....
2025-12-28 22:08:19,506 - utils.model_loader - INFO - LLM loading...
2025-12-28 22:08:19,507 - utils.model_loader - INFO - Loading model from provider: google
2025-12-28 22:08:19,507 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-28 22:08:19,580 - agent.agentic_workflow - INFO - Building state graph
2025-12-28 22:08:19,585 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-28 22:08:19,885 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-28 22:08:19,887 - agent.agentic_workflow - INFO - Agent function called
2025-12-28 22:08:54,157 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
During task with name 'agent' and id 'b1975926-9f51-7b88-bf2c-b5b0780c4fbe'
2025-12-29 09:39:28,764 - main - INFO - Received query: Parie gidecegim restorant öner
2025-12-29 09:39:28,764 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-29 09:39:28,765 - utils.model_loader - INFO - Loaded config.....
2025-12-29 09:39:28,766 - utils.model_loader - INFO - LLM loading...
2025-12-29 09:39:28,766 - utils.model_loader - INFO - Loading model from provider: google
2025-12-29 09:39:28,766 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-29 09:39:28,879 - agent.agentic_workflow - INFO - Building state graph
2025-12-29 09:39:28,885 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-29 09:39:29,316 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-29 09:39:29,319 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:40:04,133 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
During task with name 'agent' and id 'cb2fd0b1-c21c-e4d0-15d6-d3450bb856ec'
2025-12-29 09:40:54,667 - main - INFO - Received query: Parie gidecegim restorant öner
2025-12-29 09:40:54,667 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-29 09:40:54,667 - utils.model_loader - INFO - Loaded config.....
2025-12-29 09:40:54,668 - utils.model_loader - INFO - LLM loading...
2025-12-29 09:40:54,668 - utils.model_loader - INFO - Loading model from provider: google
2025-12-29 09:40:54,668 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-29 09:40:54,768 - agent.agentic_workflow - INFO - Building state graph
2025-12-29 09:40:54,774 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-29 09:40:55,061 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-29 09:40:55,064 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:41:30,233 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. ', 'status': 'RESOURCE_EXHAUSTED'}}
During task with name 'agent' and id '5ba2323e-4462-bced-87d4-bf882063c912'
2025-12-29 09:51:35,762 - main - INFO - Received query: parise gidecegim restorant öner
2025-12-29 09:51:35,762 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-29 09:51:35,762 - utils.model_loader - INFO - Loaded config.....
2025-12-29 09:51:35,764 - utils.model_loader - INFO - LLM loading...
2025-12-29 09:51:35,764 - utils.model_loader - INFO - Loading model from provider: google
2025-12-29 09:51:35,764 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-29 09:51:35,883 - agent.agentic_workflow - INFO - Building state graph
2025-12-29 09:51:35,889 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-29 09:51:36,271 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-29 09:51:36,273 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:51:37,586 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 09:51:43,011 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:51:48,337 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 09:51:48,339 - main - INFO - Query processed successfully
2025-12-29 09:52:42,775 - main - INFO - Received query: şimdi parise 5 günlük tatil planı hazırla bana her şey yapacagım ona göre bir plan hazırla
2025-12-29 09:52:42,775 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-29 09:52:42,775 - utils.model_loader - INFO - Loaded config.....
2025-12-29 09:52:42,776 - utils.model_loader - INFO - LLM loading...
2025-12-29 09:52:42,776 - utils.model_loader - INFO - Loading model from provider: google
2025-12-29 09:52:42,776 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-29 09:52:42,849 - agent.agentic_workflow - INFO - Building state graph
2025-12-29 09:52:42,853 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-29 09:52:43,194 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-29 09:52:43,195 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:52:46,166 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 09:52:50,829 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:53:02,578 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 09:53:02,582 - main - ERROR - Error processing query: can't multiply sequence by non-int of type 'float'
Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 799, in _func
    outputs = list(
        executor.map(self._run_one, tool_calls, input_types, tool_runtimes)
    )
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ~~~~~~~~~~^^^^^^^^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/usr/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/config.py", line 551, in _wrapped_fn
    return contexts.pop().run(fn, *args)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 1010, in _run_one
    return self._execute_tool_sync(tool_request, input_type, config)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 959, in _execute_tool_sync
    content = _handle_tool_error(e, flag=self._handle_tool_errors)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 424, in _handle_tool_error
    content = flag(e)  # type: ignore [assignment, call-arg]
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 381, in _default_handle_tool_errors
    raise e
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 916, in _execute_tool_sync
    response = tool.invoke(call_args, config)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/base.py", line 629, in invoke
    return self.run(tool_input, **kwargs)
           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/base.py", line 981, in run
    raise error_to_raise
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/base.py", line 947, in run
    response = context.run(self._run, *tool_args, **tool_kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/structured.py", line 93, in _run
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/tools/expense_calculator_tool.py", line 15, in estimate_total_hotel_cost
    return self.calculator.multiply(price_per_night, total_days)
           ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/utils/expense_calculator.py", line 14, in multiply
    return a * b
           ~~^~~
TypeError: can't multiply sequence by non-int of type 'float'
During task with name 'tools' and id 'ae1c4ad2-cc92-d1a8-2fe2-582a27352152'
2025-12-29 09:54:55,213 - main - INFO - Received query: şimdi parise 5 günlük tatil planı hazırla bana her şey yapacagım ona göre bir plan hazırla
2025-12-29 09:54:55,214 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-29 09:54:55,214 - utils.model_loader - INFO - Loaded config.....
2025-12-29 09:54:55,215 - utils.model_loader - INFO - LLM loading...
2025-12-29 09:54:55,215 - utils.model_loader - INFO - Loading model from provider: google
2025-12-29 09:54:55,215 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-29 09:54:55,341 - agent.agentic_workflow - INFO - Building state graph
2025-12-29 09:54:55,347 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-29 09:54:55,636 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-29 09:54:55,638 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:54:59,624 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 09:55:04,838 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:55:43,602 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 09:55:43,603 - main - INFO - Query processed successfully
2025-12-29 09:59:05,144 - main - INFO - Received query: şimdi istanbul 5 günlük tatil planı hazırla bana her şey yapacagım ona göre bir plan hazırla
2025-12-29 09:59:05,144 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-29 09:59:05,145 - utils.model_loader - INFO - Loaded config.....
2025-12-29 09:59:05,146 - utils.model_loader - INFO - LLM loading...
2025-12-29 09:59:05,146 - utils.model_loader - INFO - Loading model from provider: google
2025-12-29 09:59:05,146 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-29 09:59:05,230 - agent.agentic_workflow - INFO - Building state graph
2025-12-29 09:59:05,234 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-29 09:59:05,601 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-29 09:59:05,603 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:59:07,843 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 09:59:08,175 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:59:09,378 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 09:59:14,170 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:59:31,088 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 09:59:31,094 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 09:59:38,664 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 09:59:39,044 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 10:00:08,157 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 10:00:08,158 - main - INFO - Query processed successfully
2025-12-29 10:02:44,043 - main - INFO - Received query: Paris'e 5 günlük bir seyahat planlamak istiyorum.  İlgi Alanlarım: Tarihi müzeler (özellikle Louvre), sokak lezzetleri ve akşamları nehir kenarı yürüyüşleri. Beklentilerim:  Günlük Plan: Sabah, öğle ve akşam için detaylı rota. Maliyet: Orta seviye bir bütçem var. Lütfen Otel, Yemek ve Müze girişleri için tahmini bir fiyat dökümü ve toplam bütçe hesabı çıkar. Hava Durumu: Gideceğim tarihlerdeki (yakın zaman) hava durumunu kontrol et. Öneriler: Özellikle "turist tuzağı" olmayan, yerel halkın gittiği 2 restoran öner.
2025-12-29 10:02:44,044 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-29 10:02:44,044 - utils.model_loader - INFO - Loaded config.....
2025-12-29 10:02:44,045 - utils.model_loader - INFO - LLM loading...
2025-12-29 10:02:44,045 - utils.model_loader - INFO - Loading model from provider: google
2025-12-29 10:02:44,045 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-29 10:02:44,138 - agent.agentic_workflow - INFO - Building state graph
2025-12-29 10:02:44,144 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-29 10:02:44,428 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-29 10:02:44,430 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 10:02:48,484 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 10:02:48,784 - agent.agentic_workflow - INFO - Agent function called
2025-12-29 10:03:18,519 - agent.agentic_workflow - INFO - LLM response received
2025-12-29 10:03:18,520 - main - INFO - Query processed successfully
2025-12-30 12:45:28,921 - main - INFO - Received query: Bana diyarbakırda gidilecek turistik yerleri ve restoranları göster
2025-12-30 12:45:28,926 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 12:45:28,926 - utils.model_loader - INFO - Loaded config.....
2025-12-30 12:45:28,927 - utils.model_loader - INFO - LLM loading...
2025-12-30 12:45:28,927 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 12:45:28,927 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 12:45:29,065 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 12:45:29,071 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 12:45:29,593 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 12:45:29,595 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 12:45:30,725 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 12:45:35,979 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 12:45:48,361 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 12:45:48,363 - main - INFO - Query processed successfully
2025-12-30 12:46:48,640 - main - INFO - Received query: paris de gidebilecegim müzeleri söyleyebilirmisin 5 günlük bir tatil yapacagım
2025-12-30 12:46:48,640 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 12:46:48,640 - utils.model_loader - INFO - Loaded config.....
2025-12-30 12:46:48,641 - utils.model_loader - INFO - LLM loading...
2025-12-30 12:46:48,641 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 12:46:48,641 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 12:46:48,716 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 12:46:48,721 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 12:46:49,038 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 12:46:49,040 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 12:46:51,579 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 12:46:57,278 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 12:47:04,035 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 12:47:04,040 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 12:47:39,050 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 12:47:39,051 - main - INFO - Query processed successfully
2025-12-30 12:54:00,479 - main - INFO - Received query: paris de gidebilecegim müzeleri söyleyebilirmisin 5 günlük bir tatil yapacagım türk lirasın açevir ama
2025-12-30 12:54:00,479 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 12:54:00,480 - utils.model_loader - INFO - Loaded config.....
2025-12-30 12:54:00,480 - utils.model_loader - INFO - LLM loading...
2025-12-30 12:54:00,481 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 12:54:00,481 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 12:54:00,565 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 12:54:00,570 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 12:54:00,987 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 12:54:00,988 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 12:54:05,215 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 12:54:10,714 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 12:54:44,307 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 12:54:44,765 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 12:55:08,656 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 12:55:08,657 - main - INFO - Query processed successfully
2025-12-30 12:56:16,413 - main - INFO - Received query: parise gidecegim bana en minumum tutarda tatil yapacagım ona göre bir plan ayarla
2025-12-30 12:56:16,414 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 12:56:16,414 - utils.model_loader - INFO - Loaded config.....
2025-12-30 12:56:16,414 - utils.model_loader - INFO - LLM loading...
2025-12-30 12:56:16,415 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 12:56:16,415 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 12:56:16,488 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 12:56:16,494 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 12:56:16,827 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 12:56:16,829 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 12:56:21,420 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 12:56:27,462 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 12:57:07,165 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 12:57:07,166 - main - INFO - Query processed successfully
2025-12-30 13:07:10,044 - main - INFO - Received query: istanbulda gidebilecegim restorant fiyatlarını getir orta fiyatlı olsun
2025-12-30 13:07:10,044 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 13:07:10,044 - utils.model_loader - INFO - Loaded config.....
2025-12-30 13:07:10,045 - utils.model_loader - INFO - LLM loading...
2025-12-30 13:07:10,045 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 13:07:10,045 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 13:07:10,156 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 13:07:10,162 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 13:07:10,565 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 13:07:10,567 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:07:11,870 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:07:17,399 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:07:23,133 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:07:23,134 - main - INFO - Query processed successfully
2025-12-30 13:07:32,671 - main - INFO - Received query: istanbulda gidebilecegim restorant fiyatlarını getir orta fiyatlı olsun fiyatlarınıda yaz
2025-12-30 13:07:32,672 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 13:07:32,672 - utils.model_loader - INFO - Loaded config.....
2025-12-30 13:07:32,673 - utils.model_loader - INFO - LLM loading...
2025-12-30 13:07:32,673 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 13:07:32,673 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 13:07:32,750 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 13:07:32,755 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 13:07:33,051 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 13:07:33,053 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:07:34,524 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:07:40,644 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:07:49,860 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:07:49,861 - main - INFO - Query processed successfully
2025-12-30 13:10:10,536 - main - INFO - Received query: kayseri de  5 günlük tatil yapacagım bana gezebilecegim konaklayabilecegim yemek yiyebilecegim yerleri öner amam benim bütçem 20000 TL 
2025-12-30 13:10:10,536 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 13:10:10,536 - utils.model_loader - INFO - Loaded config.....
2025-12-30 13:10:10,537 - utils.model_loader - INFO - LLM loading...
2025-12-30 13:10:10,537 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 13:10:10,537 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 13:10:10,611 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 13:10:10,617 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 13:10:10,906 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 13:10:10,908 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:10:13,826 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:10:14,331 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:10:48,498 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:10:48,499 - main - INFO - Query processed successfully
2025-12-30 13:13:01,045 - main - INFO - Received query: liverpool  de  5 günlük tatil yapacagım bana gezebilecegim konaklayabilecegim yemek yiyebilecegim yerleri öner amam benim bütçem 20000 TL 
2025-12-30 13:13:01,045 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 13:13:01,045 - utils.model_loader - INFO - Loaded config.....
2025-12-30 13:13:01,046 - utils.model_loader - INFO - LLM loading...
2025-12-30 13:13:01,046 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 13:13:01,046 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 13:13:01,118 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 13:13:01,123 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 13:13:01,569 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 13:13:01,570 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:13:03,821 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:13:09,759 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:13:16,007 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:13:16,439 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:13:40,996 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:13:40,997 - main - INFO - Query processed successfully
2025-12-30 13:22:09,758 - main - INFO - Received query: Kaş, Antalya için 3 günlük bir gezi planla. Orta bütçeli olsun
2025-12-30 13:22:09,759 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 13:22:09,759 - utils.model_loader - INFO - Loaded config.....
2025-12-30 13:22:09,760 - utils.model_loader - INFO - LLM loading...
2025-12-30 13:22:09,760 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 13:22:09,760 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 13:22:09,880 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 13:22:09,885 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 13:22:10,281 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 13:22:10,283 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:22:12,390 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:22:12,709 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:22:16,690 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:22:22,651 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:22:58,217 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 2.005594331s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '2s'}]}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 2.005594331s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '2s'}]}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 2.005594331s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '2s'}]}}
During task with name 'agent' and id '5df039b9-3c05-b468-3c26-ff57b9afee55'
2025-12-30 13:24:51,918 - main - INFO - Received query: Kaş, Antalya için 3 günlük bir gezi planla. Orta bütçeli olsun.
2025-12-30 13:24:51,919 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 13:24:51,919 - utils.model_loader - INFO - Loaded config.....
2025-12-30 13:24:51,920 - utils.model_loader - INFO - LLM loading...
2025-12-30 13:24:51,920 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 13:24:51,920 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 13:24:52,036 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 13:24:52,042 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 13:24:52,362 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 13:24:52,364 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:24:54,798 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:24:55,113 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:24:56,436 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:25:01,936 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:25:04,116 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:25:08,765 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:25:10,435 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:25:15,505 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:25:27,238 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:25:27,239 - main - INFO - Query processed successfully
2025-12-30 13:27:43,372 - main - INFO - Received query: Kaş, Antalya için 3 günlük bir gezi planla. Orta bütçeli olsun.
2025-12-30 13:27:43,373 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 13:27:43,373 - utils.model_loader - INFO - Loaded config.....
2025-12-30 13:27:43,374 - utils.model_loader - INFO - LLM loading...
2025-12-30 13:27:43,374 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 13:27:43,374 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 13:27:43,491 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 13:27:43,497 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 13:27:44,069 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 13:27:44,072 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:27:48,574 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:27:55,536 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:28:25,339 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:28:25,346 - main - ERROR - Error processing query: CalculatorTool._setup_tools.<locals>.calculate_total_expense() got an unexpected keyword argument 'costs'
Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 799, in _func
    outputs = list(
        executor.map(self._run_one, tool_calls, input_types, tool_runtimes)
    )
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ~~~~~~~~~~^^^^^^^^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/usr/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/config.py", line 551, in _wrapped_fn
    return contexts.pop().run(fn, *args)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 1010, in _run_one
    return self._execute_tool_sync(tool_request, input_type, config)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 959, in _execute_tool_sync
    content = _handle_tool_error(e, flag=self._handle_tool_errors)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 424, in _handle_tool_error
    content = flag(e)  # type: ignore [assignment, call-arg]
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 381, in _default_handle_tool_errors
    raise e
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/prebuilt/tool_node.py", line 916, in _execute_tool_sync
    response = tool.invoke(call_args, config)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/base.py", line 629, in invoke
    return self.run(tool_input, **kwargs)
           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/base.py", line 981, in run
    raise error_to_raise
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/base.py", line 947, in run
    response = context.run(self._run, *tool_args, **tool_kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/tools/structured.py", line 93, in _run
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
TypeError: CalculatorTool._setup_tools.<locals>.calculate_total_expense() got an unexpected keyword argument 'costs'
During task with name 'tools' and id 'f9d1cf78-9bc1-6b71-34ea-b877d6d6f3a7'
2025-12-30 13:30:02,895 - main - INFO - Received query: Kaş, Antalya için 3 günlük bir gezi planla. Orta bütçeli olsun.
2025-12-30 13:30:02,895 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2025-12-30 13:30:02,895 - utils.model_loader - INFO - Loaded config.....
2025-12-30 13:30:02,896 - utils.model_loader - INFO - LLM loading...
2025-12-30 13:30:02,896 - utils.model_loader - INFO - Loading model from provider: google
2025-12-30 13:30:02,896 - utils.model_loader - INFO - Loading LLM from Google..............
2025-12-30 13:30:03,007 - agent.agentic_workflow - INFO - Building state graph
2025-12-30 13:30:03,013 - agent.agentic_workflow - INFO - Graph compiled successfully
2025-12-30 13:30:03,356 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2025-12-30 13:30:03,358 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:30:07,022 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:30:07,433 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:30:08,882 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:30:13,778 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:30:18,387 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:30:18,393 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:30:20,127 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:30:20,132 - agent.agentic_workflow - INFO - Agent function called
2025-12-30 13:30:45,074 - agent.agentic_workflow - INFO - LLM response received
2025-12-30 13:30:45,075 - main - INFO - Query processed successfully
2026-01-03 09:56:46,938 - main - INFO - Received query: Parise gezi planla
2026-01-03 09:56:46,943 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2026-01-03 09:56:46,943 - utils.model_loader - INFO - Loaded config.....
2026-01-03 09:56:46,944 - utils.model_loader - INFO - LLM loading...
2026-01-03 09:56:46,944 - utils.model_loader - INFO - Loading model from provider: google
2026-01-03 09:56:46,944 - utils.model_loader - INFO - Loading LLM from Google..............
2026-01-03 09:56:47,067 - agent.agentic_workflow - INFO - Building state graph
2026-01-03 09:56:47,070 - agent.agentic_workflow - INFO - Graph compiled successfully
2026-01-03 09:56:47,381 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2026-01-03 09:56:47,383 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 09:56:51,888 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 09:56:56,882 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 09:57:04,067 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 09:57:04,267 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 09:57:31,922 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 09:57:31,922 - main - INFO - Query processed successfully
2026-01-03 10:02:52,686 - main - INFO - Received query: Paris'e 3 günlük sanat ve gastronomi gezisi planla
2026-01-03 10:02:52,686 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2026-01-03 10:02:52,686 - utils.model_loader - INFO - Loaded config.....
2026-01-03 10:02:52,687 - utils.model_loader - INFO - LLM loading...
2026-01-03 10:02:52,687 - utils.model_loader - INFO - Loading model from provider: google
2026-01-03 10:02:52,687 - utils.model_loader - INFO - Loading LLM from Google..............
2026-01-03 10:02:52,729 - agent.agentic_workflow - INFO - Building state graph
2026-01-03 10:02:52,733 - agent.agentic_workflow - INFO - Graph compiled successfully
2026-01-03 10:02:54,419 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2026-01-03 10:02:54,421 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 10:02:56,841 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 10:03:05,236 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 10:03:45,400 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 10:03:45,402 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 10:04:11,799 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 10:04:11,799 - main - INFO - Query processed successfully
2026-01-03 10:04:11,801 - main - INFO - Received query: Paris'e 3 günlük sanat ve gastronomi gezisi planla
2026-01-03 10:04:11,801 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2026-01-03 10:04:11,801 - utils.model_loader - INFO - Loaded config.....
2026-01-03 10:04:11,802 - utils.model_loader - INFO - LLM loading...
2026-01-03 10:04:11,802 - utils.model_loader - INFO - Loading model from provider: google
2026-01-03 10:04:11,802 - utils.model_loader - INFO - Loading LLM from Google..............
2026-01-03 10:04:11,842 - agent.agentic_workflow - INFO - Building state graph
2026-01-03 10:04:11,845 - agent.agentic_workflow - INFO - Graph compiled successfully
2026-01-03 10:04:12,082 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2026-01-03 10:04:12,083 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 10:04:15,981 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 10:04:16,226 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 10:04:17,423 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 10:04:22,190 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 10:04:33,609 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 10:04:33,613 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 10:04:35,949 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 10:04:35,953 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 10:04:38,114 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 10:04:38,309 - agent.agentic_workflow - INFO - Agent function called
2026-01-03 10:05:01,640 - agent.agentic_workflow - INFO - LLM response received
2026-01-03 10:05:01,641 - main - INFO - Query processed successfully
2026-01-06 18:20:08,828 - main - INFO - Received query: Önümüzdeki hafta (10-15 Mayıs tarihleri arasında) Paris'e 5 günlük bir seyahat planlamak istiyorum. Lütfen seyahatimi şu adımları takiperek planla:  Hava Durumu: Öncelikle gideceğim tarihlerde Paris'te havanın nasıl olacağını kontrol et. Mekan Keşfi: Sanat ve gastronomiye ilgi duyuyorum. Benim için şehirdeki en popüler 3 müzeyi (Attractions), denemem gereken 3 yerel restoranı (Restaurants) ve akşam yapabileceğim eğlenceli aktiviteleri bul. Ulaşım: Şehir içinde turistler için en uygun ulaşım yöntemlerini (Transportation) araştır. Bütçe Hesaplama: Aşağıdaki tahmini harcamalarımı toplayarak 5 günlük toplam maliyetimi hesapla: Müze girişleri: Toplam 60 Euro Yemek: Günlük 80 Euro (5 gün için) Ulaşım: Günlük 15 Euro (5 gün için) Konaklama: Toplam 500 Euro Döviz Çevirme: Hesapladığın bu toplam Euro tutarının güncel kurlarla kaç Türk Lirası (TRY) ve kaç Amerikan Doları (USD) ettiğini söyle. Tüm bu bilgileri birleştirerek bana detaylı bir seyahat planı sun."
2026-01-06 18:20:08,828 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2026-01-06 18:20:08,828 - utils.model_loader - INFO - Loaded config.....
2026-01-06 18:20:08,829 - utils.model_loader - INFO - LLM loading...
2026-01-06 18:20:08,829 - utils.model_loader - INFO - Loading model from provider: google
2026-01-06 18:20:08,829 - utils.model_loader - INFO - Loading LLM from Google..............
2026-01-06 18:20:09,062 - agent.agentic_workflow - INFO - Building state graph
2026-01-06 18:20:09,067 - agent.agentic_workflow - INFO - Graph compiled successfully
2026-01-06 18:20:09,637 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2026-01-06 18:20:09,643 - agent.agentic_workflow - INFO - Agent function called
2026-01-06 18:20:12,457 - agent.agentic_workflow - INFO - LLM response received
2026-01-06 18:20:12,774 - agent.agentic_workflow - INFO - Agent function called
2026-01-06 18:20:16,548 - agent.agentic_workflow - INFO - LLM response received
2026-01-06 18:20:22,896 - agent.agentic_workflow - INFO - Agent function called
2026-01-06 18:20:24,944 - agent.agentic_workflow - INFO - LLM response received
2026-01-06 18:20:30,779 - agent.agentic_workflow - INFO - Agent function called
2026-01-06 18:21:05,955 - main - ERROR - Error processing query: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 54.093551112s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}
Traceback (most recent call last):
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3040, in _generate
    response: GenerateContentResponse = self.client.models.generate_content(
                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        **request,
        ^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 5188, in generate_content
    return self._generate_content(
           ~~~~~~~~~~~~~~~~~~~~~~^
        model=model, contents=contents, config=parsed_config
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/models.py", line 3985, in _generate_content
    response = self._api_client.request(
        'post', path, request_dict, http_options
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1222, in _request
    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/darkrange/.local/lib/python3.13/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/google/genai/errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 54.093551112s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/main.py", line 63, in query_travel_agent
    output = react_app.invoke(messages)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 3068, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<10 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/main.py", line 2643, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_runner.py", line 167, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langgraph/_internal/_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/darkrange/ONEMLI/AI_Trip_Planner/agent/agentic_workflow.py", line 43, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5557, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 2529, in invoke
    return super().invoke(input, config, stop=stop, **kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 398, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 927, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 3044, in _generate
    _handle_client_error(e, request)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/darkrange/.local/lib/python3.13/site-packages/langchain_google_genai/chat_models.py", line 145, in _handle_client_error
    raise ChatGoogleGenerativeAIError(msg) from e
langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 54.093551112s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}
During task with name 'agent' and id '8f855ada-2ef6-1ea8-a147-40d3687d6ebc'
2026-01-07 21:03:28,262 - main - INFO - Received query: parise tatil planla 5 günlük
2026-01-07 21:03:28,266 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2026-01-07 21:03:28,266 - utils.model_loader - INFO - Loaded config.....
2026-01-07 21:03:28,267 - utils.model_loader - INFO - LLM loading...
2026-01-07 21:03:28,267 - utils.model_loader - INFO - Loading model from provider: google
2026-01-07 21:03:28,267 - utils.model_loader - INFO - Loading LLM from Google..............
2026-01-07 21:03:28,370 - agent.agentic_workflow - INFO - Building state graph
2026-01-07 21:03:28,373 - agent.agentic_workflow - INFO - Graph compiled successfully
2026-01-07 21:03:30,509 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2026-01-07 21:03:30,515 - agent.agentic_workflow - INFO - Agent function called
2026-01-07 21:03:32,864 - agent.agentic_workflow - INFO - LLM response received
2026-01-07 21:03:33,215 - agent.agentic_workflow - INFO - Agent function called
2026-01-07 21:03:34,216 - agent.agentic_workflow - INFO - LLM response received
2026-01-07 21:03:42,252 - agent.agentic_workflow - INFO - Agent function called
2026-01-07 21:04:22,093 - agent.agentic_workflow - INFO - LLM response received
2026-01-07 21:04:22,094 - main - INFO - Query processed successfully
2026-01-07 21:05:33,211 - main - INFO - Received query: parise 5 günlük tatil ayarla
2026-01-07 21:05:33,211 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2026-01-07 21:05:33,211 - utils.model_loader - INFO - Loaded config.....
2026-01-07 21:05:33,211 - utils.model_loader - INFO - LLM loading...
2026-01-07 21:05:33,211 - utils.model_loader - INFO - Loading model from provider: google
2026-01-07 21:05:33,211 - utils.model_loader - INFO - Loading LLM from Google..............
2026-01-07 21:05:33,248 - agent.agentic_workflow - INFO - Building state graph
2026-01-07 21:05:33,251 - agent.agentic_workflow - INFO - Graph compiled successfully
2026-01-07 21:05:34,481 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2026-01-07 21:05:34,483 - agent.agentic_workflow - INFO - Agent function called
2026-01-07 21:05:36,623 - agent.agentic_workflow - INFO - LLM response received
2026-01-07 21:05:37,022 - agent.agentic_workflow - INFO - Agent function called
2026-01-07 21:05:38,448 - agent.agentic_workflow - INFO - LLM response received
2026-01-07 21:05:44,199 - agent.agentic_workflow - INFO - Agent function called
2026-01-07 21:06:24,742 - agent.agentic_workflow - INFO - LLM response received
2026-01-07 21:06:24,744 - agent.agentic_workflow - INFO - Agent function called
2026-01-07 21:06:32,535 - agent.agentic_workflow - INFO - LLM response received
2026-01-07 21:06:32,539 - agent.agentic_workflow - INFO - Agent function called
2026-01-07 21:07:08,923 - agent.agentic_workflow - INFO - LLM response received
2026-01-07 21:07:08,924 - main - INFO - Query processed successfully
2026-01-07 21:15:14,302 - main - INFO - Received query: Sanat müzelerine odaklanan 1 günlük bir paris gezisi düzenle
2026-01-07 21:15:14,302 - agent.agentic_workflow - INFO - Initializing GraphBuilder with model provider: google
2026-01-07 21:15:14,302 - utils.model_loader - INFO - Loaded config.....
2026-01-07 21:15:14,303 - utils.model_loader - INFO - LLM loading...
2026-01-07 21:15:14,303 - utils.model_loader - INFO - Loading model from provider: google
2026-01-07 21:15:14,303 - utils.model_loader - INFO - Loading LLM from Google..............
2026-01-07 21:15:14,337 - agent.agentic_workflow - INFO - Building state graph
2026-01-07 21:15:14,340 - agent.agentic_workflow - INFO - Graph compiled successfully
2026-01-07 21:15:14,807 - main - INFO - Graph saved as 'my_graph.png' in /home/darkrange/ONEMLI/AI_Trip_Planner
2026-01-07 21:15:14,808 - agent.agentic_workflow - INFO - Agent function called
2026-01-07 21:15:31,900 - agent.agentic_workflow - INFO - LLM response received
2026-01-07 21:15:31,901 - main - INFO - Query processed successfully
